# Telecom Customer Churn Prediction

## Project Overview

This project focuses on building a production-ready machine learning pipeline
to predict telecom customer churn. The goal is to design an end-to-end ML workflow
that follows industry best practices, from data preprocessing to model training
and deployment readiness.

## Project Structure

- `data/` – dataset storage (excluded from GitHub)
- `notebooks/` – exploratory analysis and inspection
- `artifacts/` – saved models, metrics, and configs
- `scripts/` – utility scripts for data processing and model training
- `src/` – production-ready Python modules
- `features`/ – feature engineering
- `pipelines/` – ML pipelines for preprocessing and modeling
- `tests/` – unit tests (in progress)

## Project Problem Statement

The telecom industry faces significant challenges in retaining customers, as churn (customer attrition) can be costly and difficult to reverse. Predicting which customers are likely to churn allows companies to proactively implement retention strategies, such as targeted offers or customer service interventions.

## Project Goals

The primary goal of this project is to build a robust, scalable, and production-ready machine learning pipeline for predicting customer churn in the telecom industry. The pipeline will be designed with maintainability, reproducibility, and deployment readiness in mind. Recall will be prioritized as the primary metric to minimize false negatives, ensuring that most at-risk customers are identified for retention efforts, as missing churners can lead to significant revenue loss.

## Project Success Criteria

The project is considered successful if it delivers a production-ready ML pipeline that meets the following criteria:

1. The pipeline is modular, maintainable, and reproducible.
2. The model achieves an AUC-ROC of at least 80%, recall of at least 80% and precision of at least 40%.
3. The pipeline is ready for deployment and can be easily extended or modified.

## Current Progress

- The initial data exploration and cleaning were performed in Jupyter notebooks to understand the dataset, identify missing values, and handle inconsistencies. This step ensured that the data was of high quality before proceeding to model development.

- The cleaned dataset was split into training, validation and test sets to facilitate model training and evaluation.
  The test set is kept aside for final evaluation after model development.

- The numeric features were scaled using StandardScaler, and categorical features were encoded using OneHotEncoder to prepare the data for modeling.

- First modeling implemented with Logistics regression - The model achieves an AUC-ROC of 77%, indicating good discriminatory power. It prioritizes recall for churners (62%), successfully identifying most customers at risk of churn, at the expense of precision (37%). This behavior is acceptable at the baseline stage, as missing churners is typically more costly than false positives in telecom retention strategies.

- The first modeling was reimplemented again, after the correction of a wrongly applied scaling on the encoded categorical features. The new results show AUC-ROC of 77% which is the same as before, with a recall of 10% and precision of 79% for churners. This indicates the model was not able to identify most customer at risk of churn, which is not ideal. Further feature engineering and model tuning are needed to improve recall.

- Error analysis conducted to identify misclassification patterns and what was discovered was that among the false negatives (churners predicted as non-churners), a significant portion had high tenure months, low monthly charges and high total charges, indicating that long-term customers with lower bills and higher total charges were being overlooked by the model. Conversely, false positives (non-churners predicted as churners) often exhibited moderate tenure but higher monthly charges, suggesting that customers with mid-level engagement but higher costs were being misclassified.

- Error analysis was conducted again after removing the scaling for the numeric features before the baseline modeling. The new results show AUC-ROC of 85%, with a recall of 58% and precision of 62%, these indicate that false negatives (churners predicted as non-churners) tend to have long tenure months, lower monthly charges and higher total charges, suggesting that loyal customers with lower bills are being overlooked by the model. On the other hand, false positives (non-churners predicted as churners) often have short/middle tenure months, higher monthly charges, and lower total charges, indicating that customers with higher bills are being misclassified.

- Two hypothesis was formed based on the error analysis:
  1. Customers with high tenure months, low monthly charges and high total charges are less likely to churn, so the model may be misclassifying them due to their strong loyalty despite lower bills.
  2. Customers with moderate tenure but higher monthly charges may be more sensitive to price increases or service issues, leading to misclassification as churners.

- Pipeline for preprocessing and modeling built and tested on the jupyter notebook. The same result as the baseline modeling was achieved. which is AUC-ROC of 85%, with a recall of 58% and precision of 62% for churners. This indicates that the pipeline is functioning correctly and can be further enhanced with feature engineering and model tuning.

- Feature engineering in progress to create new features based on insights from error analysis. Initial features include:
  - `charges_per_months`: Average charges per month to capture billing patterns.
  - `high_monthly_charges`: Binary feature indicating if monthly charges exceed a certain threshold.
  - `change_ratio`: Ratio of total charges to tenure months to identify customers with increasing costs over time.

  - and these features have been added to the training and validation sets. The results shows AUC-ROC of 85%, with a recall of 57% and precision of 63% for churners. This indicates that the new features have not significantly improved model performance yet, further feature engineering and tuning are needed.

  - Then, the log transformation was perfomed on the Tenure months and Monthly charges features to reduce skewness and improve model performance. After applying the log transformation, the model achieved an AUC-ROC of 77%, with a recall of 57% and precision of 64% for churners. This indicates that the log transformation has slightly improved the model's precision, but unable to improve the recall. Further feature engineering and tuning are still needed.

  - statsmodels analysis was performed to identify statistically significant features. Based on the odd ratio and p-values, features such as 'Dependent_No', 'Internet Service_Fiber optic', 'Partner_No', and 'Contract_Month-to-month' were found to be significant predictors of churn. These insights will guide further feature engineering and model refinement.

  - with these insight, new features were created such as 'high monthly charges', 'single short term', (Dependent_No + 'Tenure month < 6'), 'fiber monthly' (Internet Service_Fiber optic + Contract_Month-to-month), and 'no family' (Partner_No + Dependent_No). After the evaluation it shows these features do not improve the model performance, it further worsened the recall performance to 55% and precision to 63%, except the no family feature which improved the the recall and precision to 56% and 64% respectively and still maintain the AUC-ROC of 85%. Thus, all the features created will be drop except the 'no family' feature.

  - The probability threshold was tuned to optimize the trade-off between precision and recall. By adjusting the threshold to 0.3, the model achieved a significant increment in recall of 78% from 56% and precision decrease to 52% from 64% for churners and still maintain the AUC-ROC of 85%, this is a better result because it improves the identification of at-risk customers while maintaining a reasonable level of precision.

  - Then, the pipeline preprocessing module was refactored to include the feature engineering steps using sklearn's FunctionTransformer. This modular approach allows for easier experimentation and tuning of the feature engineering process within the pipeline. and the results shows the same as before after refactoring just a slight difference in the recall, which is AUC-ROC of 85%, with a recall of 79% and precision of 52% for churners at the probability threshold of 0.3.

  - After finalizing the feature engineering and pipeline refactoring, artifacts creation was performed to save the first verson (v1) of the preprocessing pipeline and the model using joblib. This ensures that the exact preprocessing steps and trained model can be easily loaded for future predictions and deployment.

## Churn Model Version 1 (v1)

### Model Metadata

- Version: v1
- Model type: LogisticRegression
- Created by: Issa Muiz
- Date created: 2026-01-21

### Preprocessing & Feature Engineering

- Numeric features: Monthly Charges, Tenure_months_log, Total_Charges_log, no_family
- Categorical features: Gender, Senior Citizen, Partner, Dependents, Phone Service, Multiple Lines, Internet Service, Online Security, Online Backup, Device Protection, Tech Support, Streaming TV, Streaming Movies, Contract, Paperless Billing, Payment Method
- Feature Engineering applied:
  - Tenure log transformation
  - Total Charges log transformation
  - No_family binary feature creation
- Scaling: StandardScaler for numeric features
- Encoding: OneHotEncoder (ignore unknowns, sparse=False)

### Model Hyperparameters

- Solver = lbfgs
- Threshold for prediction: 0.3
- Random state: 42

### Dataset Info

- Training rows: 4214
- Validation rows: 1406
- Original columns: 21 (after cleaning & dropping)

### Metrics

- AUC-ROC: 0.85
- Recall: 0.79
- Precision: 0.51

### Artifacts

- Model: artifacts/models/churn_model_v1.pkl
- Metrics: artifacts/metrics/metrics_v1.json
- Config: artifacts/configs/config_v1.json

### Notes

- This is the baseline logistic regression model.
- Data cleaning and feature engineering are included in the pipeline.
- Threshold set to 0.3 to prioritize recall.
- Hyperparameters are yet to be tuned.
- The test set is not yet evaluated, the test set will be evaluated at the end of the project, after another version is created.

## Churn Model Version 2 (v2)

### Model Metadata

- Version: v2
- Model type: LogisticRegression
- Created by: Issa Muiz
- Date created: 2026-01-26

### Preprocessing & Feature Engineering

- Numeric features: Monthly Charges, Tenure_months_log, Total_Charges_log, no_family
- Categorical features: Gender, Senior Citizen, Partner, Dependents, Phone Service, Multiple Lines, Internet Service, Online Security, Online Backup, Device Protection, Tech Support, Streaming TV, Streaming Movies, Contract, Paperless Billing, Payment Method
- Feature Engineering applied:
  - Tenure log transformation
  - Total Charges log transformation
  - No_family binary feature creation
- Scaling: StandardScaler for numeric features
- Encoding: OneHotEncoder (ignore unknowns, sparse=False)

### Model Hyperparameters

- Solver = lbfgs
- Threshold for prediction: 0.3
- Random state: 42
- Penalty: l1
- C: 10
- Class weight: balanced

### Dataset Info

- Training rows: 4214
- Validation rows: 1406
- Original columns: 21 (after cleaning & dropping)

### Metrics

- AUC-ROC: 0.85
- Recall: 0.92
- Precision: 0.41

### Artifacts

- Model: artifacts/models/churn_model_v2.pkl
- Metrics: artifacts/metrics/metrics_v2.json
- Config: artifacts/configs/config_v2.json

### Notes

- This version refactors the logistic regression model with L1 regularization and hyperparameter tuning.
- A significant improvement in recall to 92% was achieved, making it more effective at identifying churners.
- Precision decreased to 41%, indicating more false positives, but this is acceptable given the focus on recall.
- The test set is not yet evaluated, the test set will be evaluated at the next version v3.

## Churn Model Version 3 (v3)

### Model Metadata

- Version: v3
- Model type: LogisticRegression
- Created by: Issa Muiz
- Date created: 2026-01-27

### Preprocessing & Feature Engineering

- Numeric features: Monthly Charges, Tenure_months_log, Total_Charges_log, no_family
- Categorical features: Gender, Senior Citizen, Partner, Dependents, Phone Service, Multiple Lines, Internet Service, Online Security, Online Backup, Device Protection, Tech Support, Streaming TV, Streaming Movies, Contract, Paperless Billing, Payment Method
- Feature Engineering applied:
  - Tenure log transformation
  - Total Charges log transformation
  - No_family binary feature creation
- Scaling: StandardScaler for numeric features
- Encoding: OneHotEncoder (ignore unknowns, sparse=False)

### Model Hyperparameters

- Solver = lbfgs
- Threshold for prediction: 0.3
- Random state: 42
- Penalty: l1
- C: 10
- Class weight: balanced

### Dataset Info

- Training rows: 4214
- test rows: 1406
- Original columns: 21 (after cleaning & dropping)

### Metrics

- AUC-ROC: 0.87
- Recall: 0.91
- Precision: 0.49

### Artifacts

- Model: artifacts/models/churn_model_v3.pkl
- Metrics: artifacts/metrics/metrics_v3.json
- Config: artifacts/configs/config_v3.json

### Notes

- This version is the final evaluation for the churn model using the test set which has never been introduced or fed to the model.
- The model still maintain the recall at 91% and precision was increased to 49%, making it more effective at identifying churners and predicting churn.
- The AUC-ROC also improved to 87%, indicating better overall model performance.
- With this version we have now come to the conclusion of our evaluation as we have achieve our success benchmarks of AUC-ROC of at least 80%, recall of at least 80% and precision of at least 40%.
- The next steps will involve unit testing, model packaging, deployment readiness, and planning for monitoring and maintenance.

## Stack & Tools

- Python
- jupyter Notebooks
- Pandas
- NumPy
- Matplotlib & Seaborn
- Scikit-learn
- statsmodels
- Git & GitHub
- joblib

## Project Steps

- Baseline modeling
- Error analysing
- Build full preprocessing + model pipeline
- Feature engineering
- Artifact creation
- Model training and tuning
- Final evaluation (test set)
- Unit testing
- Model packaging and deployment readiness
- Monitoring and maintenance plan

## Author

Issa Muiz
